{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic-regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevanmatovic/serbian-sentiment-analysis/blob/master/logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "xrO7ZkNdUQMR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from IPython.display import Markdown, display\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_files\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xBkJGpGtU5iA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2ea4b34-a6fb-4af5-fe7e-c1df57f0f12c"
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-MJXta57Jkaz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/final.csv')\n",
        "dfu = pd.read_csv('/content/drive/My Drive/final_upweigting.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LZ9NMyeUnN8u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_reg(x_train,y_train,x_test,y_test):\n",
        "  param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],'solver':['lbfgs', 'liblinear', 'sag', 'saga']}\n",
        "  grid = GridSearchCV(LogisticRegression(max_iter=3000), param_grid, cv=5)\n",
        "  grid.fit(x_train, y_train)\n",
        "  print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
        "  print(\"Best parameters: \", grid.best_params_)\n",
        "  print(\"Best estimator: \", grid.best_estimator_)\n",
        "  lr = grid.best_estimator_\n",
        "  y_pred = lr.predict(x_test)\n",
        "  print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jn7AX2DQWAlg",
        "colab_type": "code",
        "outputId": "4b71b001-abc8-43dc-c35d-3d220d621e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2091
        }
      },
      "cell_type": "code",
      "source": [
        "for dataset in [df,dfu]:\n",
        "    if not dataset.equals(dfu):\n",
        "        display(Markdown('<h1>Dataset without upweighting:</h1>'))\n",
        "    else:\n",
        "        display(Markdown('<h1>Dataset with upweighting:</h1>'))\n",
        "    df_x = dataset['Review']\n",
        "    df_y = dataset['Label']\n",
        "    x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=4)\n",
        "    cv_u = CountVectorizer()\n",
        "    cv_b = CountVectorizer(ngram_range=(2, 2))\n",
        "    tv = TfidfVectorizer()\n",
        "\n",
        "    unigram_train = cv_u.fit_transform(x_train)\n",
        "    unigram_test = cv_u.transform(x_test)\n",
        "    print(\"Number of features - unigram: {}\".format(len(cv_u.get_feature_names())))\n",
        "\n",
        "    bigram_train = cv_b.fit_transform(x_train)\n",
        "    bigram_test = cv_b.transform(x_test)\n",
        "    print(\"Number of features - bigram: {}\".format(len(cv_b.get_feature_names())))\n",
        "\n",
        "    tfidf_train = tv.fit_transform(x_train)\n",
        "    tfidf_test = tv.transform(x_test)\n",
        "    print(\"Number of features - tfidf: {}\".format(len(tv.get_feature_names())))\n",
        "    \n",
        "    display(Markdown('<h2>Logistic Regression(unigram vectorization):</h2>'))\n",
        "    log_reg(unigram_train,y_train,unigram_test,y_test)\n",
        "    \n",
        "    \n",
        "    display(Markdown('<h2>Logistic Regression(bigram vectorization):</h2>'))\n",
        "    log_reg(bigram_train,y_train,bigram_test,y_test)\n",
        "    \n",
        "    display(Markdown('<h2>Logistic Regression(tfidf vectorization):</h2>'))\n",
        "    log_reg(tfidf_train,y_train,tfidf_test,y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h1>Dataset without upweighting:</h1>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Number of features - unigram: 21325\n",
            "Number of features - bigram: 251583\n",
            "Number of features - tfidf: 21325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h2>Logistic Regression(unigram vectorization):</h2>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 0.93\n",
            "Best parameters:  {'C': 1, 'solver': 'sag'}\n",
            "Best estimator:  LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=3000, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='sag',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.61      0.68      1536\n",
            "           1       0.95      0.98      0.97     12343\n",
            "\n",
            "   micro avg       0.94      0.94      0.94     13879\n",
            "   macro avg       0.86      0.79      0.82     13879\n",
            "weighted avg       0.93      0.94      0.93     13879\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h2>Logistic Regression(bigram vectorization):</h2>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 0.91\n",
            "Best parameters:  {'C': 10, 'solver': 'lbfgs'}\n",
            "Best estimator:  LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=3000, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.35      0.47      1536\n",
            "           1       0.92      0.98      0.95     12343\n",
            "\n",
            "   micro avg       0.91      0.91      0.91     13879\n",
            "   macro avg       0.83      0.67      0.71     13879\n",
            "weighted avg       0.90      0.91      0.90     13879\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h2>Logistic Regression(tfidf vectorization):</h2>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 0.93\n",
            "Best parameters:  {'C': 10, 'solver': 'liblinear'}\n",
            "Best estimator:  LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=3000, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.61      0.67      1536\n",
            "           1       0.95      0.97      0.96     12343\n",
            "\n",
            "   micro avg       0.93      0.93      0.93     13879\n",
            "   macro avg       0.85      0.79      0.82     13879\n",
            "weighted avg       0.93      0.93      0.93     13879\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h1>Dataset with upweighting:</h1>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Number of features - unigram: 21325\n",
            "Number of features - bigram: 259453\n",
            "Number of features - tfidf: 21325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h2>Logistic Regression(unigram vectorization):</h2>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 0.93\n",
            "Best parameters:  {'C': 1, 'solver': 'saga'}\n",
            "Best estimator:  LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=3000, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='saga',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.63      0.69      1536\n",
            "           1       0.96      0.98      0.97     12343\n",
            "\n",
            "   micro avg       0.94      0.94      0.94     13879\n",
            "   macro avg       0.86      0.80      0.83     13879\n",
            "weighted avg       0.93      0.94      0.94     13879\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h2>Logistic Regression(bigram vectorization):</h2>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 0.92\n",
            "Best parameters:  {'C': 10, 'solver': 'lbfgs'}\n",
            "Best estimator:  LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=3000, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.43      0.54      1536\n",
            "           1       0.93      0.98      0.96     12343\n",
            "\n",
            "   micro avg       0.92      0.92      0.92     13879\n",
            "   macro avg       0.84      0.71      0.75     13879\n",
            "weighted avg       0.91      0.92      0.91     13879\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h2>Logistic Regression(tfidf vectorization):</h2>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 0.93\n",
            "Best parameters:  {'C': 10, 'solver': 'saga'}\n",
            "Best estimator:  LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=3000, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='saga',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.61      0.67      1536\n",
            "           1       0.95      0.97      0.96     12343\n",
            "\n",
            "   micro avg       0.93      0.93      0.93     13879\n",
            "   macro avg       0.85      0.79      0.81     13879\n",
            "weighted avg       0.93      0.93      0.93     13879\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GyrogQufnMwh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KtIoMtgtJ1Sp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}