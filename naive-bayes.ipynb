{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final.csv')\n",
    "dfu = pd.read_csv('final_upweigting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features - unigram: 21325\n",
      "Number of features - bigram: 259453\n",
      "Number of features - tfidf: 21325\n"
     ]
    }
   ],
   "source": [
    "df_x = dataset['Review']\n",
    "df_y = dataset['Label']\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=4)\n",
    "cv_u = CountVectorizer()\n",
    "cv_b = CountVectorizer(ngram_range=(2, 2))\n",
    "tv = TfidfVectorizer()\n",
    "\n",
    "unigram_train = cv_u.fit_transform(x_train)\n",
    "unigram_test = cv_u.transform(x_test)\n",
    "print(\"Number of features - unigram: {}\".format(len(cv_u.get_feature_names())))\n",
    "\n",
    "bigram_train = cv_b.fit_transform(x_train)\n",
    "bigram_test = cv_b.transform(x_test)\n",
    "print(\"Number of features - bigram: {}\".format(len(cv_b.get_feature_names())))\n",
    "\n",
    "tfidf_train = tv.fit_transform(x_train)\n",
    "tfidf_test = tv.transform(x_test)\n",
    "print(\"Number of features - tfidf: {}\".format(len(tv.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Multinomial naive bayes - Count vectorizer(bigrams):\n",
      "Dataset without upweighting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71      1536\n",
      "           1       0.97      0.95      0.96     12343\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     13879\n",
      "   macro avg       0.82      0.85      0.83     13879\n",
      "weighted avg       0.94      0.93      0.93     13879\n",
      "\n",
      "Dataset with upweighting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71      1536\n",
      "           1       0.97      0.95      0.96     12343\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     13879\n",
      "   macro avg       0.82      0.85      0.83     13879\n",
      "weighted avg       0.94      0.93      0.93     13879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Multinomial naive bayes - Count vectorizer(unigram):')\n",
    "for dataset in [df,dfu]:\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(unigram_train,y_train)\n",
    "    y_pred = mnb.predict(unigram_test)\n",
    "    if dataset.equals(df):\n",
    "        print('Dataset without upweighting:')\n",
    "    else:\n",
    "        print('Dataset with upweighting:')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial naive bayes - Count vectorizer(bigram):\n",
      "Dataset without upweighting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.49      0.61      1536\n",
      "           1       0.94      0.98      0.96     12343\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     13879\n",
      "   macro avg       0.87      0.74      0.78     13879\n",
      "weighted avg       0.92      0.93      0.92     13879\n",
      "\n",
      "Dataset with upweighting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.49      0.61      1536\n",
      "           1       0.94      0.98      0.96     12343\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     13879\n",
      "   macro avg       0.87      0.74      0.78     13879\n",
      "weighted avg       0.92      0.93      0.92     13879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Multinomial naive bayes - Count vectorizer(bigram):')\n",
    "for dataset in [df,dfu]:\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(bigram_train,y_train)\n",
    "    y_pred = mnb.predict(bigram_test)\n",
    "    if dataset.equals(df):\n",
    "        print('Dataset without upweighting:')\n",
    "    else:\n",
    "        print('Dataset with upweighting:')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial naive bayes - tfidf vectorizer(bigram):\n",
      "Dataset without upweighting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.21      0.34      1536\n",
      "           1       0.91      1.00      0.95     12343\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     13879\n",
      "   macro avg       0.91      0.60      0.64     13879\n",
      "weighted avg       0.91      0.91      0.88     13879\n",
      "\n",
      "Dataset with upweighting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.21      0.34      1536\n",
      "           1       0.91      1.00      0.95     12343\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     13879\n",
      "   macro avg       0.91      0.60      0.64     13879\n",
      "weighted avg       0.91      0.91      0.88     13879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Multinomial naive bayes - tfidf vectorizer(bigram):')\n",
    "for dataset in [df,dfu]:\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(tfidf_train,y_train)\n",
    "    y_pred = mnb.predict(tfidf_test)\n",
    "    if dataset.equals(df):\n",
    "        print('Dataset without upweighting:')\n",
    "    else:\n",
    "        print('Dataset with upweighting:')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression unigram:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-38f6bacc1d05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best cross-validation score: {:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameters: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    649\u001b[0m                 \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         scorers, self.multimetric_ = _check_multimetric_scoring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[1;34m(cv, y, classifier)\u001b[0m\n\u001b[0;32m   2056\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2057\u001b[0m         if (classifier and (y is not None) and\n\u001b[1;32m-> 2058\u001b[1;33m                 (type_of_target(y) in ('binary', 'multiclass'))):\n\u001b[0m\u001b[0;32m   2059\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;31m# Invalid inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m     if y.ndim > 2 or (y.dtype == object and len(y) and\n\u001b[0m\u001b[0;32m    271\u001b[0m                       not isinstance(y.flat[0], string_types)):\n\u001b[0;32m    272\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'unknown'\u001b[0m  \u001b[1;31m# [[[1, 2]]] or [obj_1] and not [\"label_1\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "for X_train,y_train in zip([unigram_train,bigram_train,tfidf_train],[unigram_test,bigram_test,tfidf_test]):\n",
    "    if y_train != bigram_train and y_train != tfidf_train:\n",
    "        print('Logistic regression unigram:')\n",
    "    elif y_train != unigram_train and y_train != tfidf_train:\n",
    "        print('Logistic regression bigram:')\n",
    "    else:\n",
    "        print('Logistic regression tfidf:')\n",
    "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "    grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "    print(\"Best parameters: \", grid.best_params_)\n",
    "    print(\"Best estimator: \", grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 2), ('c', 3)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 11121)\t0.3568763535872376\n",
      "  (0, 5535)\t0.3944259624643877\n",
      "  (0, 19475)\t0.6341989904711426\n",
      "  (0, 14239)\t0.26645438424840356\n",
      "  (0, 11958)\t0.38849746196058427\n",
      "  (0, 15781)\t0.30484562000247\n",
      "  (1, 16675)\t0.36871134224277724\n",
      "  (1, 20629)\t0.2225893213791065\n",
      "  (1, 12491)\t0.25041996231941366\n",
      "  (1, 17634)\t0.07213181942985183\n",
      "  (1, 8400)\t0.1663023096718336\n",
      "  (1, 8471)\t0.11962203968167277\n",
      "  (1, 446)\t0.16526264904752205\n",
      "  (1, 4951)\t0.14859653037869072\n",
      "  (1, 14594)\t0.14296762150702433\n",
      "  (1, 11280)\t0.1582291277756016\n",
      "  (1, 7846)\t0.09284477826595333\n",
      "  (1, 16245)\t0.12307640118929133\n",
      "  (1, 3448)\t0.11117162035536511\n",
      "  (1, 8328)\t0.1425651400271848\n",
      "  (1, 19112)\t0.0932098180312117\n",
      "  (1, 9017)\t0.12651282669145347\n",
      "  (1, 12358)\t0.1720942131090385\n",
      "  (1, 5613)\t0.2644354799471694\n",
      "  (1, 9814)\t0.09543751270744943\n",
      "  :\t:\n",
      "  (55511, 11641)\t0.101809614764793\n",
      "  (55511, 13237)\t0.09850712054350076\n",
      "  (55511, 12440)\t0.19901809366715353\n",
      "  (55511, 3196)\t0.0931806668279754\n",
      "  (55511, 18500)\t0.08637591289125433\n",
      "  (55511, 6573)\t0.08538331780149093\n",
      "  (55511, 13546)\t0.21280855027289042\n",
      "  (55511, 1461)\t0.10579649737331893\n",
      "  (55511, 17811)\t0.12006245370572523\n",
      "  (55511, 16969)\t0.12006245370572523\n",
      "  (55511, 4515)\t0.11823591172809508\n",
      "  (55511, 18922)\t0.11823591172809508\n",
      "  (55511, 13804)\t0.12486683758034599\n",
      "  (55511, 9010)\t0.24973367516069198\n",
      "  (55511, 14570)\t0.13307998606199703\n",
      "  (55511, 19998)\t0.13307998606199703\n",
      "  (55511, 7691)\t0.13307998606199703\n",
      "  (55511, 17836)\t0.13307998606199703\n",
      "  (55512, 11121)\t0.4997542525006974\n",
      "  (55512, 19626)\t0.2342646105015199\n",
      "  (55512, 17367)\t0.8338859510592803\n",
      "  (55513, 19112)\t0.2479907627255553\n",
      "  (55513, 20238)\t0.28591678484558236\n",
      "  (55513, 4474)\t0.6034901005126014\n",
      "  (55513, 7629)\t0.7018203989124656\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
